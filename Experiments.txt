# Experiment descriptions


# Experiment 0: Recreating the poster

Simulation::  
    - Visual: linear wrt days with slope of -0.2 and random intercept between 14 and 18  
    - Symptom: linear wrt visual score with random intercept (mean 6, stdev 2) and slope (1, 2, or 3)  
    - Error: none or multiplicative (+- 30% or +-50%)  
    - npops=1000  
    - npersons=1000  
Filter:: 
    None  
Sample:: 
    Fixed 
    - 7 14 28 or
    - 7 14 90
    SmilePoster
    - index is day 7 and has score sx_idx
    - sample 1 is at day in [8, 89] and has score in (0.7*sx_idx, sx_idx) and is day 8 if no other option
    - sample 2 is at day in (day sample 1, last study day] and has score (min sx, 0.4*sx_idx) and is day_sample_1 + 1 or last study day if no other option
    - sample 3 is at day in (day sample 2, last study day] and is last study day if no other option
Regression:: 
    Mixed effects with random intercept  

Purpose:: 
    Recreate the data from the previous experiments summarized in the poster, to weed out coding errors or simulation/methodology discrepencies  
Hypothesis:: 
    Bias will be the same as the poster.  
Reasoning:: 
    Based on the same ideas  



## Experiment 1-4: Fixed effects



### Experiment 1: Baselines

Simulation::  
    - Visual score is linear wrt days with random intercept and slope per person  
    - Symptom: linear wrt visual score with fixed intercept and slope (>1)  
    - Error: none or multiplicative (+-50%) or additive (+-5)  
    - npops=100  
    - npersons=100  
Filter:: 
    None  
Sample:: 
    None  
Regression:: 
    Simple person-wise linear or mixed effects with random intercept and slope  

Purpose:: 
    Evaluate the bias in an idealized, full-information setting. Evaluate the difference between different regression models in the absence of random effects in the population.  
Hypothesis:: 
    There will be no bias in noerror or multiplicative error. There will be a small bias towards a slower (lower) slope in additive error. This will be the same for both regressions.  
Reasoning:: 
    The relationship is linear, no persons are discarded from the population, each person will have at least two points to describe their straight line. Multiplicative error will cancel out. However, for additive errors, the enduring error when the visual score is recovered will lead to more observations at (VMIN, +s) without equivalents at (VMIN, -s) to balance them out since the symptoms have a lower bound (see thick vertical line on the left of the graph of visual vs symptom).
  
  
NOTE: Kinks in line of visual score or of symptom no error score due to discretization of time do not contribute to bias because they happen identically to both. The effect produced by these kinks are that points forming the line of symptom noerror vs visual are slightly sparser at low values.
  
  
### Experiment 2: Basic filtering

Simulation:: 
    Same as previous experiment  
Filter:: 
    Recover before day 8 and after 90  
Sample:: 
    None  
Regression:: 
    Mixed effects with random intercept and slope  

Purpose:: 
    Evaluate bias in a full-information setting but keeping only studiable people.  
Hypothesis:: 
    Bias will be unchanged from baseline (previous experiment).
Reasoning:: 
    Filtering removes entire people, but each person has the the same slope for symptoms before error and errors are generated in the same way for each person.  


### Experiment 3: Traditional sampling

Simulation:: 
    Same as previous experiment  
Filter:: 
    Same as previous experiment (before day 8 and after day 90)  
Sample:: 
    Days 8, 30, 90  
Regression:: 
    Same as previous experiment  

Purpose::  
    Evaluate bias in a traditional, fixed-interval study.  
Hypothesis::  
    Bias in no error and multiplicative error will be unchanged from previous experiment, although the distributions will be slightly more spread out. Bias in additive error will be increased.  
Reasoning::  
    Traditional sampling would not create any bias in no error and multiplicative error, as filtering ensures there will be enough distinct points per person (>2) to uniquely determine a line, while the nature of the errors won't be changed. Distributions will be slightly more spread out, as a sparse amount of points per person will make it difficult to average out the errors per person, but these will still be averaged out on the population level and the populationList level. For additive errors, the thick vertical bar at v=VMIN will be oversampled (on people who recover before 90 days) compared to the more accurate points at higher visual scores, which was the original source of bias. (This could possibly be mitigated by filtering differently.)  


### Experiment 4: SMILE sampling  

Simulation::  
    Same as previous experiment
Filter::  
    Same as previous experiment (before day 8 and after day 90)  
Sample::  
    Index at day 8, then take symptom score 0 days after reaching 70% and 30% of index  
    Alternatively, same with +5 days after reaching or a random number in [1, 14] days after reaching  
Regression::  
    Same as previous experiment  

Purpose::  
    Evaluate bias due to sampling with SMILE technique across different appointment timing schemes
Hypothesis::  
    When taking "appointments" at +0 days, the intercept would be noticeably biased towards lower values for both error types. For multiplicative error, the slope would also be biased towards lower values, whereas for additive errors it wouldn't get that bias. For +5 days or +random days, that bias would not be present. 
Reasoning::  
    Measuring as soon as the person feels better (i.e. +0 days) makes it more likely to measure when the error is pushing the person down, and so the intercept would decrease and the slope would either increase or decrease, depending on if the visual score at the affected point is low or high respectively. In the case of multiplicative, most errors happen early on (high visual score), so the slope would likely decrease. For additive error, it could go either way. If the bias is measured after waiting some days, the bias disappears since the errors are generated independently each day.  
    
NOTE: A higher slope combined with long appoitment times could cause more samples at VMIN, which may lead to lower slope estimates for additive error (due to the same reason as in Experiment 1).



## Experiments 5-8: random effects

Simulations::
    Same as previous experiments, but each person has a random symptom-vs-visual slope and VMIN from a using (left-truncated) normal distributions. The product of the slope and VMIN determines the intercept, but that intercept's pdf is non-Gaussian (see here: https://math.stackexchange.com/a/397716) 

Purposes::
    Evaluate sources of bias due to random effects and its interactions other aspects.


### Experiment 5:  

Simulation::  
    Same as experiment 1, but varying slope and VMIN per person 
Filter:: 
    Same as experiment 1 (None)  
Sample:: 
    Same as experiment 1 (None)  
Regression:: 
    Same as experiment 1 (Simple person-wise linear or mixed effects with random intercept and slope)  

Purpose:: 
    Evaluate the bias in an idealized, full-information setting. Evaluate the difference between different regression models in the absence of random effects in the population.  
Hypothesis:: 
    Results will be identical to experiment 1, but more spread out.  
Reasoning:: 
    The slopes and intercepts will have mean equivalent to the fixed values from experiment 1. Bias due to additive errors at VMIN will be decreased in persons with low slopes, but equivalently increased in persons witl high slopes.



NOTE: Maybe allow error of additive to drop to zero when v=VMIN? No, keep as is.
NOTE: Maybe dditive error should be correlated to slope?
NOTE: if methodology wants to sample after the study is "over" (e.g. at pop.ndays+4) due to the time delay of scheduling an appointment, what should happen? should it be a NaN (current, easy), or should the sampling proceed (by generating new scores for that specific day, complicated)